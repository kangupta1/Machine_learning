{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-aJfoLvD3ZH"
      },
      "source": [
        "## Seung Jun Choi in Urban Information Lab\n",
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNodZ8lvD3ZI",
        "outputId": "72739600-a2d4-46bc-bf95-8e8f45c4d9b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "NumPy version: 2.0.2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgSIfceED3ZI",
        "outputId": "d4eb9f78-7d6e-441c-d379-b0f4af5dcce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "# If you haven't downloaded sklearn...\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co_Ko79dD3ZJ"
      },
      "source": [
        "*italicized text*![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O_kpJlCD3ZJ",
        "outputId": "167a0c1b-d8be-4c63-cb9f-d16c2a59ecbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arTOoVhAD3ZJ"
      },
      "source": [
        "### How to evaluate your models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpzP1KHDD3ZJ"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Y4HxEpD3ZJ"
      },
      "source": [
        "### Regression Model Evaluation is easier than Other Model Evaluation (It is also more intuitive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCYjNCV2D3ZJ"
      },
      "source": [
        "Because all you have to do is calculate the loss of model's prediction to real or validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5sPPwwxD3ZK"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf_dbKV4D3ZK"
      },
      "source": [
        "### Here we will focus more on Classification Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFHFPbp2D3ZK"
      },
      "source": [
        "#### Import BaseEstimator from sklearn.\n",
        "#### BaseEstimator help you create Customized dummy Classifier Classes\n",
        "#### We use fit() to train model; however, in BaseEstimator fit doesn't really mean anything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c2-uR0CsD3ZK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "     #The model here is just prediction the sex; which is classified into binary dummy (1 vs 0)\n",
        "    def fit(self, X , y=None):\n",
        "        pass\n",
        "\n",
        "\n",
        "    #If the value of the sex feature is 1 , it would return 0 if not it would return 1\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros( ( X.shape[0], 1 ))\n",
        "        for i in range (X.shape[0]) :\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else :\n",
        "                pred[i] = 1\n",
        "\n",
        "        return pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwSHnhHeD3ZK"
      },
      "source": [
        "We will use the created BaseEstimator for modelling classifier model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7noGLWsD3ZK"
      },
      "source": [
        "Here I will be using titanic sample data which is downloadable in Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZlEKwbMD3ZK"
      },
      "source": [
        "# Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ-JFY6TD3ZK",
        "outputId": "05087062-54ab-4d9d-f2ee-1eae745406c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Install pandas incase you do not have it\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zYHmM-GHD3ZK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Prepross null values\n",
        "def fillna(df):\n",
        "    df = df.fillna({\n",
        "    'Age': df['Age'].mean(),\n",
        "    'Cabin': 'N',\n",
        "    'Embarked': 'N',\n",
        "    'Fare': 0\n",
        "    })\n",
        "    return df\n",
        "\n",
        "# delete features not in need\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
        "    return df\n",
        "\n",
        "# labeling the strings to numeric dummies\n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin','Sex','Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "# calling out the features transformation functions that I have previously defined\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obw5Qb71D3ZK"
      },
      "source": [
        "# 1. First let's look at Accuracy of your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "sDOb6LPoD3ZK",
        "outputId": "6914807c-f6b9-4b9f-d08e-64ffdae27626"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3436459163.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# calling out the data, preprocessing data, and training and spliting your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtitanic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_titanic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitanic_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_titanic_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtitanic_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# calling out the data, preprocessing data, and training and spliting your model\n",
        "titanic_df = pd.read_csv('./train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
        "                                                  test_size=0.2, random_state=0)\n",
        "\n",
        "# using the dummyclassifier model I have made above\n",
        "myclf = MyDummyClassifier()\n",
        "myclf.fit(X_train ,y_train)\n",
        "\n",
        "mypredictions = myclf.predict(X_test)\n",
        "print('Dummy Classifier Accuaracy is\" : {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euu3VYx4D3ZL"
      },
      "source": [
        "## What is Accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKe6CL0qD3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDf8bCf5D3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAO9OJQJD3ZL"
      },
      "source": [
        "### There other indicators we use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fllDvVmJD3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfKdTmGCD3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWICYo-wD3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQtjP_KeD3ZL"
      },
      "source": [
        "### Chossing the evaluation score depends on your research objective. For instance if you modelling cancer classification risk of doing false negative is higher than doing false positive; meaning model identifying even though you have cancer and not capturing it is riskier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0EKT2xnD3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWSJj_N7D3ZL"
      },
      "source": [
        "### In this case Recall is more significant indicator than precision (Positive > Negative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeKBRQzLD3ZL"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqHIlCDD3ZL"
      },
      "source": [
        "## Decent model is having higher score in both recall and precision score; however they are actually in tradeoff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwSpvu8xD3ZL"
      },
      "source": [
        "# 2. Let's get both precision & recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmlLxjaJD3ZL"
      },
      "source": [
        "### I'm going to define some functions for convenience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1BEDBCMD3ZL"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator):\n",
        "    def fit(self,X,y):\n",
        "        pass\n",
        "\n",
        "    def predict(self,X):\n",
        "        return np.zeros( (len(X), 1) , dtype=bool)\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "print(digits.data)\n",
        "print(\"### digits.data.shape:\", digits.data.shape)\n",
        "print(digits.target)\n",
        "print(\"### digits.target.shape:\", digits.target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmexcnOHD3ZL"
      },
      "outputs": [],
      "source": [
        "y = (digits.target == 7).astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)\n",
        "fakeclf = MyFakeClassifier()\n",
        "fakeclf.fit(X_train , y_train)\n",
        "fakepred = fakeclf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2I2eVw_2D3ZM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, fakepred))\n",
        "print(\"Recall:\", recall_score(y_test, fakepred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNqee1HTD3ZM"
      },
      "source": [
        "## Below is the code to get all confusion matrix (accuracy / precision / recall )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQikj1uiD3ZM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
        "\n",
        "def get_clf_eval(y_test , pred):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    print('Confusion Matrix')\n",
        "    print(confusion)\n",
        "    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}'.format(accuracy , precision ,recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wZsS7nLD3ZM"
      },
      "source": [
        "#### I'm going to use titanic data from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jL-oCoc3D3ZM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Because dependent variable is binary; I'm using logisticregression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# reload, preprocess\n",
        "titanic_df = pd.read_csv('./train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
        "                                                    test_size=0.20, random_state=11)\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "\n",
        "lr_clf.fit(X_train , y_train)\n",
        "pred = lr_clf.predict(X_test)\n",
        "get_clf_eval(y_test , pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kPVR7HID3ZM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCZ9o52pD3ZN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSZPU38ND3ZN"
      },
      "outputs": [],
      "source": [
        "#install matplotlib incase you do not have it\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQsHUTlyD3ZN"
      },
      "source": [
        "And as I said the precision and recall score are in trade-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNBLWYtrD3ZN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
        "    # get precision and recall ndarray per thresholds\n",
        "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
        "\n",
        "    # Set X-axis as thresholds; Y-axis for Precision & Recall\n",
        "    plt.figure(figsize=(8,6))\n",
        "    threshold_boundary = thresholds.shape[0]\n",
        "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
        "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
        "\n",
        "    # Plot X-axis in 0.1 interval\n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "\n",
        "    # xSetting label, legend, and grid\n",
        "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "    plt.legend(); plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4onVPOh4D3ZN"
      },
      "source": [
        "## 1) Method to incrase your precision\n",
        "#### Strengthen your positive index. For instance, only diagnose cancer when you are 100% sure (older than 80, obesitiy, cancer cell size in 99% percentile). Precision equation is TP / (TP + FP). So if you get only one positive patient the score became 100%\n",
        "\n",
        "## 2) Method to increase your recall\n",
        "#### Diagnoe every patients as positive beacuse TN is not included in the matrix and FN is 0. Either way your score become 100%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nbQNNcDD3ZN"
      },
      "source": [
        "## But of course everything should be balanced..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70LwtBCDD3ZN"
      },
      "source": [
        "# 3. F1 Score: Mixture of Precision & Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaltRmBTD3ZN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test , pred)\n",
        "print('F1 Score: {0:.4f}'.format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YciEWiAzD3ZN"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_cc3CgfD3ZN"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test , pred):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    # Adding F1 Score\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    print('Confusion Matrix')\n",
        "    print(confusion)\n",
        "    # f1 score print\n",
        "    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
        "\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
        "    # thresholds\n",
        "    for custom_threshold in thresholds:\n",
        "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
        "        custom_predict = binarizer.transform(pred_proba_c1)\n",
        "        print('thresholds:',custom_threshold)\n",
        "        get_clf_eval(y_test , custom_predict)\n",
        "\n",
        "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqnAPJruD3ZN"
      },
      "source": [
        "#### thresholds 0.6; the F1 score is at the highest; however, do note that recall score is lacking behind than other thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a83nu5GD3ZN"
      },
      "source": [
        "## Lastly. ROC Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X2SUH0xD3ZO"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9STCq7pD3ZO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "def roc_curve_plot(y_test , pred_proba_c1):\n",
        "    # calculate TPR, FPR per thresholds\n",
        "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
        "\n",
        "    # Plot data\n",
        "    plt.plot(fprs , tprs, label='ROC')\n",
        "    # Linear line\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "\n",
        "    # legend\n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "    plt.xlim(0,1); plt.ylim(0,1)\n",
        "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6cdNKUD3ZO"
      },
      "source": [
        "## You can actually calcuate the area (AUC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYu0z3aYD3ZO"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar9WPPgXD3ZO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
        "roc_score = roc_auc_score(y_test, pred_proba)\n",
        "print('ROC AUC value: {0:.4f}'.format(roc_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lCwZfcID3ZO"
      },
      "source": [
        "### There is also something called PR Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVzxReHjD3ZO"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9frI0gRAD3ZO"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFuQ0kv2D3ZO"
      },
      "source": [
        "## How should I calculate PR AUC?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr3RL9W2D3ZO"
      },
      "source": [
        "### Well, I'll leave it as a homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ5KM-O8D3ZO"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}